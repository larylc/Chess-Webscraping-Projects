{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd013b2b11727bf160dd71a59e0dab29eb839e69decf1cbe92d304a571428e1e58f",
   "display_name": "Python 3.8.8 32-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# The Path to Chess Masterhood\n",
    "\n",
    "## Motivation \n",
    "\n",
    "As an expansion of the first chess web scraping project (\"Elite Chess Grandmaster Web Scraping Project\"), the goal for this project is to produce another large data set that combines player attributes with rating history. This time, we are interested in chess players rated 2200-2847. \n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "Along with chess ratings comes the possibility of being titled. Chess players that have successfully reached 2200 usually receive the title of chess master. The goal for this project is to try to get a dataset that represents the rating progression of various chess master titles. See the following links for information about ratings:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Elo_rating_system \n",
    "- https://en.wikipedia.org/wiki/Chess_title \n",
    "\n",
    "\n",
    "\n",
    "## Limitations \n",
    "\n",
    "It is important to mention that some chess titles can be achieved under a rating of 2200. Additionally, not all players above 2200 choose to acquire their titles. Moreover, chess masters that have already earned their titles can dip under the 2200 threshold. The reason this 2200 cutoff was chosen is because of the sheer size of the data set. As chess players get weaker the amount of chess players drastically increases. To illustrate using the attribute data set used in this project, there are only 949 chess players above 2500. If we include chess players 2200 and above the number skyrockets to 20,763. As we shall see in this project, extracting each recorded rating for these 20,700 chess players quickly produces an extremely large data table with over 3 million rows. \n",
    "\n",
    "Therefore, for the sake of keeping this data set manageable, we are only going to extract chess players that represent \"master strength.\" Because the web scraping method I am using takes over 7 hours to extract the rating histories of 20,000 chess players from [fide.com](https://ratings.fide.com/), I am choosing to extract the chess players in 4 separate batches based on rating intervals. Trying to separate the players by titles would take too much time to verify. Because some chess players are banned or are under investigation, they need to be filtered out so the web scraping functions can perform their tasks. Verifying chess player status by rating intervals proved to be the most efficient method. \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Acquisition \n",
    "\n",
    "Similar to the first web scraping project, we need to web-scrape rating history data from the [world chess federation website](https://ratings.fide.com/) and combine it with the attribute data that we get from downloading the May chess player rating list. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "from requests_html import HTMLSession\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in FIDE player characteristics (sex, federation, etc)\n",
    "file = 'players_list_foa_may.txt'\n",
    "chess = pd.read_fwf(file)"
   ]
  },
  {
   "source": [
    "Because trying to filter for all chess players above 2200 creates a ridiculously large data frame that creates memory errors later on. The solution I came up with was to split the table into smaller more manageable rating intervals. My plan is to eventually merge all the tables together at the very end."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for chess players across various rating ranges\n",
    "chess_players_2200s =  chess[(chess[\"SRtng\"] >= 2200 ) &  (chess[\"SRtng\"] < 2300 ) ]\n",
    "chess_players_2300s =  chess[(chess[\"SRtng\"] >= 2300 ) &  (chess[\"SRtng\"] < 2400 ) ]\n",
    "chess_players_2400s =  chess[(chess[\"SRtng\"] >= 2400 ) &  (chess[\"SRtng\"] < 2500 ) ]\n",
    "chess_players_2500s_plus =  chess[chess[\"SRtng\"] >= 2500]"
   ]
  },
  {
   "source": [
    "This time instead of web scraping URLs directly from the top chess player rating list, we wil be using the ID Numbers of chess players to create URLs that will directly take us to chess player rating histories. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that excludes problematic chess players \n",
    "def exclude_players(data):\n",
    "    data_clean = data[(data[\"ID Number\"] != 11600098) & (data[\"ID Number\"] != 14108836) & (data[\"ID Number\"] != 14106329) & (data[\"ID Number\"] != 929662) & (data[\"ID Number\"] != 901202)]\n",
    "    return(data_clean)\n",
    "## Function that creates list of chess player urls using chess player ids  \n",
    "def create_prepped_urls(data):\n",
    "    player_ids = list(data[\"ID Number\"])\n",
    "    player_ids_strings= [str(ids) for ids in player_ids]\n",
    "    player_urls_prepped = ['https://ratings.fide.com/profile/' + id + '/chart' for id in player_ids_strings]\n",
    "    return(player_urls_prepped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the 2200 chess player urls \n",
    "chess_players_2200s_clean = exclude_players(chess_players_2200s)\n",
    "chess_players_2200s_urls = create_prepped_urls(chess_players_2200s_clean)\n",
    "\n",
    "# Prepare the 2300 chess player urls \n",
    "chess_players_2300s_clean = exclude_players(chess_players_2300s)\n",
    "chess_players_2300s_urls = create_prepped_urls(chess_players_2300s_clean)\n",
    "\n",
    "# Prepare the 2400 chess player urls \n",
    "chess_players_2400s_clean = exclude_players(chess_players_2400s)\n",
    "chess_players_2400s_urls = create_prepped_urls(chess_players_2400s_clean)\n",
    "\n",
    "# Prepare the 2500 chess player and above urls \n",
    "chess_players_2500s_plus_clean = exclude_players(chess_players_2500s_plus)\n",
    "chess_players_2500s_plus_clean_urls = create_prepped_urls(chess_players_2500s_plus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim function used to eventually set FIDE ids as the key for the tables so that I can merge history and characteristics data\n",
    "def trim_url(x):\n",
    "    y = int(x.replace(\"https://ratings.fide.com/profile/\", \"\").replace('/chart',\"\"))\n",
    "    return(y)\n",
    "\n"
   ]
  },
  {
   "source": [
    "The two next blocks were used to store player rating histories in a dictionary. I created a function that web scrapes each chess playerâ€™s FIDE webpage for their rating progression and uses id as the key for each table nested in the dictionary.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts chess player rating history tables from fide website and stores them in dictionary using player ids as the keys\n",
    "def extract_player_rating_history(links):\n",
    "    player_stats = {}\n",
    "    for link in links: \n",
    "        id=trim_url(link)\n",
    "        page = requests.get(link).text\n",
    "        dfs = pd.read_html(page, attrs = {'class' : 'profile-table profile-table_chart-table'})\n",
    "        player_stats[id] = dfs[0]\n",
    "    return(player_stats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "For transparency, this next block is how I found specific player pages that could not be scraped (because they were banned, under investigation, or had an error with their ID on FIDE's website). I checked each rating interval using this function (the tedious process will not be shown). This next block performs the same task as the extraction function above except it returns the problematic chess players' webpages.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "player_stats = {}\n",
    "for link in all_player_urls_prepped: \n",
    "    id=trim_url(link)\n",
    "    page = requests.get(link).text\n",
    "    try: \n",
    "        dfs = pd.read_html(page, attrs = {'class' : 'profile-table profile-table_chart-table'})\n",
    "    except ValueError:\n",
    "        print(\"Error:\" + link )\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform rating history extraction for 2200s\n",
    "chess_player_2200s_history = extract_player_rating_history(chess_players_2200s_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Perform rating history extraction for 2300s\n",
    "chess_player_2300s_history = extract_player_rating_history(chess_players_2300s_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Perform rating history extraction for 2400s\n",
    "chess_player_2400s_history = extract_player_rating_history(chess_players_2400s_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Perform rating history extraction for 2500 and above\n",
    "chess_player_2500s_plus_history = extract_player_rating_history(chess_players_2500s_plus_clean_urls)\n"
   ]
  },
  {
   "source": [
    "The next step is to create an ID Number column using the ID keys that were assigned to each nested table in the dictionaries because we want to eventually perform a merge of these rating tables and the attributes from the first data frames."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates an ID Number Column for each table and sets all values in that column  to the key of the table\n",
    "def attach_id(chess_player_2500s_history):\n",
    "    tags = chess_player_2500s_history.keys()\n",
    "    for tag in tags: \n",
    "        chess_player_2500s_history[tag][\"ID Number\"] = tag\n",
    "    return chess_player_2500s_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform id attachement for 2200s\n",
    "chess_player_2200s_history_with_id = attach_id(chess_player_2200s_history)\n",
    "\n",
    "#Perform id attachement for 2300s\n",
    "chess_player_2300s_history_with_id = attach_id(chess_player_2300s_history)\n",
    "\n",
    "#Perform id attachement for 2400s\n",
    "chess_player_2400s_history_with_id = attach_id(chess_player_2400s_history)\n",
    "\n",
    "#Perform id attachement for 2500s and above \n",
    "chess_player_2500s_plus_history_with_id = attach_id(chess_player_2500s_plus_history)"
   ]
  },
  {
   "source": [
    "Now let's free the tables from the dictionaries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction for turning dictionary into list and then turning list into a massive dataframe\n",
    "def convert_dict_to_df(players_history): \n",
    "    list_of_player_dfs= list(players_history.values())\n",
    "    all_player_stats_table= list_of_player_dfs[0].append(list_of_player_dfs[1:-1])\n",
    "    return(all_player_stats_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform conversion for 2200s \n",
    "player_stat_table_2200s= convert_dict_to_df(chess_player_2200s_history_with_id)\n",
    "\n",
    "# Perform conversion for 2300s \n",
    "player_stat_table_2300s= convert_dict_to_df(chess_player_2300s_history_with_id)\n",
    "\n",
    "# Perform conversion for 2400s \n",
    "player_stat_table_2400s= convert_dict_to_df(chess_player_2400s_history_with_id)\n",
    "\n",
    "# Perform conversion for 2500s and above\n",
    "player_stat_table_2500s_plus= convert_dict_to_df(chess_player_2500s_plus_history_with_id)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Part of what made this project difficult was the amount of memory that was required for each of these tables. The next few blocks significantly reduce the amount of memory by cutting out unnecessary columns from the rating history and attribute tables. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 12038 entries, 410 to 998884\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   ID Number  12038 non-null  int64 \n 1   Name       12038 non-null  object\n 2   Tit        4802 non-null   object\n 3   Fed        12038 non-null  object\n 4   Sex        12038 non-null  object\n 5   B-day      12038 non-null  int64 \ndtypes: int64(2), object(4)\nmemory usage: 470.2+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "player_stat_table_2500s_plus_cut = player_stat_table_2500s_plus[[\"Period\",\"ID Number\", \"RTNG\",\"RAPID RTNG\", \"BLITZ RTNG\"]]\n",
    "chess_players_2500s_plus_attributes_clean= chess_players_2500s_plus_clean[['ID Number','Tit', 'Name', 'Fed', 'Sex', 'B-day']]\n",
    "\n",
    "player_stat_table_2400s_cut = player_stat_table_2400s[[\"Period\",\"ID Number\", \"RTNG\",\"RAPID RTNG\", \"BLITZ RTNG\"]]\n",
    "chess_players_2400s_attributes_clean= chess_players_2400s_clean[['ID Number', 'Name','Tit', 'Fed', 'Sex', 'B-day']]\n",
    "\n",
    "\n",
    "player_stat_table_2300s_cut = player_stat_table_2300s[[\"Period\",\"ID Number\", \"RTNG\",\"RAPID RTNG\", \"BLITZ RTNG\"]]\n",
    "chess_players_2300s_attributes_clean= chess_players_2300s_clean[['ID Number', 'Name','Tit', 'Fed', 'Sex', 'B-day']]\n",
    "\n",
    "player_stat_table_2200s_cut = player_stat_table_2200s[[\"Period\",\"ID Number\", \"RTNG\",\"RAPID RTNG\", \"BLITZ RTNG\"]]\n",
    "chess_players_2200s_attributes_clean= chess_players_2200s_clean[['ID Number', 'Name','Tit', 'Fed', 'Sex', 'B-day']]\n"
   ]
  },
  {
   "source": [
    "Here come the final merges and filters to create our final tables. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that merges attribute data from above with the rating history data \n",
    "def merging_tables(attributes, history):\n",
    "    masters_table = attributes.merge(history, on= \"ID Number\", how= \"outer\")\n",
    "#Filter to get rid of single chess player records \n",
    "    masters_table_filtered = masters_table[masters_table[\"ID Number\"].map(masters_table[\"ID Number\"].value_counts()) > 1]\n",
    "    return(masters_table_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1792173 entries, 0 to 1792173\nData columns (total 10 columns):\n #   Column      Dtype  \n---  ------      -----  \n 0   ID Number   int64  \n 1   Name        object \n 2   Tit         object \n 3   Fed         object \n 4   Sex         object \n 5   B-day       int64  \n 6   Period      object \n 7   RTNG        object \n 8   RAPID RTNG  float64\n 9   BLITZ RTNG  float64\ndtypes: float64(2), int64(2), object(6)\nmemory usage: 109.4+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Perform final merge and filter for 2200s\n",
    "masters_table_filtered_2200s= merging_tables(chess_players_2200s_attributes_clean, player_stat_table_2200s_cut)\n",
    "print(masters_table_filtered_2200s.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 827419 entries, 0 to 827418\nData columns (total 10 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   ID Number   827419 non-null  int64  \n 1   Name        827419 non-null  object \n 2   Tit         652041 non-null  object \n 3   Fed         827419 non-null  object \n 4   Sex         827419 non-null  object \n 5   B-day       827419 non-null  int64  \n 6   Period      827419 non-null  object \n 7   RTNG        825716 non-null  float64\n 8   RAPID RTNG  226458 non-null  float64\n 9   BLITZ RTNG  223783 non-null  float64\ndtypes: float64(3), int64(2), object(5)\nmemory usage: 53.7+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Perform final merge and filter for 2300s\n",
    "masters_table_filtered_2300s= merging_tables(chess_players_2300s_attributes_clean, player_stat_table_2300s_cut)\n",
    "print(masters_table_filtered_2300s.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 327970 entries, 0 to 327969\nData columns (total 10 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   ID Number   327970 non-null  int64  \n 1   Name        327970 non-null  object \n 2   Tit         309229 non-null  object \n 3   Fed         327970 non-null  object \n 4   Sex         327970 non-null  object \n 5   B-day       327970 non-null  int64  \n 6   Period      327970 non-null  object \n 7   RTNG        327269 non-null  float64\n 8   RAPID RTNG  122842 non-null  float64\n 9   BLITZ RTNG  125498 non-null  float64\ndtypes: float64(3), int64(2), object(5)\nmemory usage: 21.3+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Perform final merge and filter for 2400s\n",
    "masters_table_filtered_2400s= merging_tables(chess_players_2400s_attributes_clean, player_stat_table_2400s_cut)\n",
    "print(masters_table_filtered_2400s.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 145669 entries, 0 to 145668\nData columns (total 10 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   ID Number   145669 non-null  int64  \n 1   Tit         144894 non-null  object \n 2   Name        145669 non-null  object \n 3   Fed         145669 non-null  object \n 4   Sex         145669 non-null  object \n 5   B-day       145669 non-null  int64  \n 6   Period      145669 non-null  object \n 7   RTNG        145565 non-null  float64\n 8   RAPID RTNG  75478 non-null   float64\n 9   BLITZ RTNG  77358 non-null   float64\ndtypes: float64(3), int64(2), object(5)\nmemory usage: 9.4+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform final merge and filter for 2500s\n",
    "masters_table_filtered_2500s= merging_tables(chess_players_2500s_plus_attributes_clean, player_stat_table_2500s_plus_cut)\n",
    "print(masters_table_filtered_2500s.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3093231 entries, 0 to 3093230\nData columns (total 10 columns):\n #   Column      Dtype  \n---  ------      -----  \n 0   ID Number   int64  \n 1   Name        object \n 2   Tit         object \n 3   Fed         object \n 4   Sex         object \n 5   B-day       int64  \n 6   Period      object \n 7   RTNG        object \n 8   RAPID RTNG  float64\n 9   BLITZ RTNG  float64\ndtypes: float64(2), int64(2), object(6)\nmemory usage: 165.2+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "all_chess_masters_table = pd.concat([masters_table_filtered_2200s, masters_table_filtered_2300s,masters_table_filtered_2400s, masters_table_filtered_2500s],ignore_index= True)\n",
    "print(all_chess_masters_table.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final table as csv\n",
    "all_chess_masters_table.to_csv(\"all_chess_masters.csv\")\n"
   ]
  },
  {
   "source": [
    "# Sources \n",
    "\n",
    "For chess player ratings for the month of may check out: \n",
    "https://ratings.fide.com/download_lists.phtml"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}